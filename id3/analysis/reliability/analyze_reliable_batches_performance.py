#!/usr/bin/env python3
"""


"""

import json
import os
import sys
from pathlib import Path
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def analyze_batch_performance(batch_dir: Path) -> Dict:

    results = {
        'batch_name': batch_dir.name,
        'lagrangian': {'files': [], 'accessibility': [], 'final_accessibility': []},
        'ams': {'files': [], 'accessibility': [], 'final_accessibility': []},
        'cpc': {'files': [], 'accessibility': [], 'final_accessibility': []}
    }
    

    for method in ['lagrangian', 'ams', 'cpc']:
        method_files = list(batch_dir.glob(f"*{method}*.json"))
        results[method]['file_count'] = len(method_files)
        

        sample_files = method_files[:50] if len(method_files) > 50 else method_files
        
        for file_path in sample_files:
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                best_acc = data.get('best_accessibility', None)
                final_acc = data.get('final_accessibility', None)
                
                if best_acc is not None:
                    results[method]['accessibility'].append(best_acc)
                    results[method]['files'].append(file_path.name)
                
                if final_acc is not None:
                    results[method]['final_accessibility'].append(final_acc)
                    
            except Exception as e:

                continue
    
    return results

def calculate_statistics(values: List[float]) -> Dict:
    """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
    if not values:
        return {
            'count': 0,
            'mean': None,
            'median': None,
            'std': None,
            'min': None,
            'max': None,
            'p99': None,
            'p99.9': None,
            'p99.99': None,
            'excellent_rate': None,  # < 1.0
            'good_rate': None,       # < 1.5
            'acceptable_rate': None  # < 2.0
        }
    
    arr = np.array(values)
    
    return {
        'count': len(values),
        'mean': np.mean(arr),
        'median': np.median(arr),
        'std': np.std(arr),
        'min': np.min(arr),
        'max': np.max(arr),
        'p99': np.percentile(arr, 99) if len(arr) >= 100 else np.max(arr),
        'p99.9': np.percentile(arr, 99.9) if len(arr) >= 1000 else np.max(arr),
        'p99.99': np.percentile(arr, 99.99) if len(arr) >= 10000 else np.max(arr),
        'excellent_rate': np.mean(arr < 1.0) * 100,  # < 1.0 kcal/mol
        'good_rate': np.mean(arr < 1.5) * 100,       # < 1.5 kcal/mol  
        'acceptable_rate': np.mean(arr < 2.0) * 100  # < 2.0 kcal/mol
    }

def generate_comparison_table(batch_results: List[Dict]) -> pd.DataFrame:

    comparison_data = []
    
    for batch in batch_results:
        batch_name = batch['batch_name']
        
        for method in ['lagrangian', 'ams', 'cpc']:
            method_data = batch[method]
            

            best_stats = calculate_statistics(method_data['accessibility'])
            

            final_stats = calculate_statistics(method_data['final_accessibility'])
            
            comparison_data.append({



                






                






            })
    
    return pd.DataFrame(comparison_data)

def check_parameter_consistency(batch_results: List[Dict]) -> Dict:
    """æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§å’Œç»“æœé‡ç°æ€§"""
    consistency_report = {
        'parameter_analysis': {},
        'result_consistency': {},
        'recommendations': []
    }
    

    cai_batches = [b for b in batch_results if 'cai' in b['batch_name'].lower()]
    access_batches = [b for b in batch_results if 'access' in b['batch_name'].lower()]
    
    consistency_report['parameter_analysis'] = {
        'cai_batches': len(cai_batches),
        'access_batches': len(access_batches),
        'total_batches': len(batch_results)
    }
    

    if len(access_batches) >= 2:
        batch1 = access_batches[0]
        batch2 = access_batches[1]
        
        for method in ['lagrangian', 'ams', 'cpc']:
            stats1 = calculate_statistics(batch1[method]['accessibility'])
            stats2 = calculate_statistics(batch2[method]['accessibility'])
            
            if stats1['mean'] and stats2['mean']:
                diff = abs(stats1['mean'] - stats2['mean'])
                relative_diff = diff / stats1['mean'] * 100
                
                consistency_report['result_consistency'][f'{method}_mean_diff'] = {
                    'absolute_diff': diff,
                    'relative_diff_percent': relative_diff,
                    'consistent': relative_diff < 10.0
                }
    
    return consistency_report

def main():
    reliable_dir = Path("å¯é å®éªŒç»“æœ")
    
    if not reliable_dir.exists():
        print("âŒ å¯é å®éªŒç»“æœç›®å½•ä¸å­˜åœ¨")
        return
    
    print("ğŸ” åˆ†æä¸‰ä¸ªå¯ä¿¡æ‰¹æ¬¡çš„è¯¦ç»†æ€§èƒ½")
    print("=" * 80)
    
    batch_results = []
    

    for batch_dir in sorted(reliable_dir.iterdir()):
        if batch_dir.is_dir():
            print(f"\nğŸ“Š åˆ†ææ‰¹æ¬¡: {batch_dir.name}")
            
            result = analyze_batch_performance(batch_dir)
            batch_results.append(result)
            

            for method in ['lagrangian', 'ams', 'cpc']:
                count = result[method]['file_count']
                if count > 0:
                    stats = calculate_statistics(result[method]['accessibility'])
                    print(f"   {method.upper()}: {count}ä¸ªæ–‡ä»¶, æœ€ä½³={stats['min']:.3f}, å‡å€¼={stats['mean']:.3f}")
    

    print(f"\nğŸ“ˆ ä¸‰ä¸ªæ‰¹æ¬¡æ€§èƒ½å¯¹æ¯”è¡¨æ ¼")
    print("=" * 80)
    
    comparison_df = generate_comparison_table(batch_results)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    pd.set_option('display.max_colwidth', 15)
    print(comparison_df.to_string(index=False))
    

    print(f"\nğŸ” å‚æ•°ä¸€è‡´æ€§å’Œç»“æœé‡ç°æ€§åˆ†æ")
    print("=" * 80)
    
    consistency = check_parameter_consistency(batch_results)
    
    print(f"æ‰¹æ¬¡ç»„æˆ:")
    print(f"   CAIå®éªŒæ‰¹æ¬¡: {consistency['parameter_analysis']['cai_batches']} ä¸ª")
    print(f"   Accesså®éªŒæ‰¹æ¬¡: {consistency['parameter_analysis']['access_batches']} ä¸ª")
    print(f"   æ€»æ‰¹æ¬¡æ•°: {consistency['parameter_analysis']['total_batches']} ä¸ª")
    
    if consistency['result_consistency']:
        print(f"\nä¸¤ä¸ªAccessæ‰¹æ¬¡ç»“æœä¸€è‡´æ€§:")
        for method_key, consistency_data in consistency['result_consistency'].items():
            method_name = method_key.replace('_mean_diff', '').upper()
            is_consistent = "âœ… ä¸€è‡´" if consistency_data['consistent'] else "âŒ ä¸ä¸€è‡´"
            print(f"   {method_name}: ç›¸å¯¹å·®å¼‚ {consistency_data['relative_diff_percent']:.1f}% {is_consistent}")
    

    print(f"\nğŸ¯ æ€§èƒ½ç­‰çº§è¯„ä¼° (åŸºäºæœ€ä½³å€¼)")
    print("=" * 80)
    
    for batch in batch_results:
        print(f"\næ‰¹æ¬¡: {batch['batch_name']}")
        for method in ['lagrangian', 'ams', 'cpc']:
            stats = calculate_statistics(batch[method]['accessibility'])
            if stats['min'] is not None:
                if stats['min'] < 1.0:
                    level = "ğŸŒŸ ä¼˜ç§€"
                elif stats['min'] < 1.5:
                    level = "âœ… è‰¯å¥½"
                elif stats['min'] < 2.0:
                    level = "âš ï¸ å¯æ¥å—"
                else:
                    level = "âŒ éœ€æ”¹è¿›"
                
                print(f"   {method.upper()}: {stats['min']:.3f} kcal/mol {level}")
    
    return batch_results

if __name__ == "__main__":
    main()