#!/usr/bin/env python3
"""


"""

import json
import sys
import os
from pathlib import Path
import numpy as np
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor, as_completed
from multiprocessing import cpu_count

def process_experiment_file(file_info):
    """

    file_info: (result_file_path, protein, constraint, variant, seed)
    """
    result_file, protein, constraint, variant, seed = file_info

    try:
        with open(result_file) as f:
            data = json.load(f)


        return {
            'protein': data.get('protein_name', protein),
            'constraint': constraint,
            'variant': variant,
            'seed': seed,
            'best_accessibility': data.get('best_accessibility', float('inf')),
            'amino_acids_match': data.get('amino_acids_match', False),
            'amino_acids_correct': data.get('amino_acids_correct', 0.0),
            'final_accessibility': data.get('final_accessibility', float('inf')),
            'improvement': data.get('improvement', 0.0),
            'file_path': str(result_file)
        }
    except Exception as e:
        print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {result_file}: {e}")
        return None

def collect_experiment_files(mpi_results_dir: Path):
    """


    """
    file_info_list = []


    seed_dirs = list(mpi_results_dir.glob("seed*"))

    for seed_dir in seed_dirs:
        seed_num = int(seed_dir.name.replace('seed', ''))


        worker_dirs = list(seed_dir.glob("worker*"))

        for worker_dir in worker_dirs:


            worker_name = worker_dir.name
            parts = worker_name.split('_')
            if len(parts) >= 4:
                variant = parts[1][1:]  # v00 -> 00
                constraint = parts[3][1:]  # clagrangian -> lagrangian


                protein_dirs = [d for d in worker_dir.iterdir() if d.is_dir()]

                for protein_dir in protein_dirs:

                    protein_name_from_dir = protein_dir.name.split('_')[0]


                    json_files = [f for f in protein_dir.glob("*.json")
                                if not f.name.startswith(('config', 'progress', 'summary'))]

                    if json_files:
                        result_file = json_files[0]
                        file_info_list.append((
                            result_file,
                            protein_name_from_dir,
                            constraint,
                            variant,
                            seed_num
                        ))

    return file_info_list

def generate_mpi_summary_table(mpi_results_dir: Path, output_csv: Path = None, num_workers: int = None):
    """


    """
    print(f"ğŸ” æ±‡æ€»MPIå®éªŒç»“æœ: {mpi_results_dir}")

    if num_workers is None:
        num_workers = min(cpu_count(), 32)

    print(f"ä½¿ç”¨ {num_workers} ä¸ªå¹¶è¡Œè¿›ç¨‹")


    print("ğŸ“ æ”¶é›†å®éªŒæ–‡ä»¶...")
    file_info_list = collect_experiment_files(mpi_results_dir)

    if not file_info_list:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å®éªŒæ–‡ä»¶")
        return None

    print(f"æ‰¾åˆ° {len(file_info_list)} ä¸ªå®éªŒæ–‡ä»¶")


    print("âš¡ å¹¶è¡Œå¤„ç†å®éªŒæ–‡ä»¶...")
    all_results = []
    result_dict = defaultdict(list)  # {(protein, constraint, variant): [values]}

    with ProcessPoolExecutor(max_workers=num_workers) as executor:

        future_to_file = {executor.submit(process_experiment_file, file_info): file_info for file_info in file_info_list}


        completed = 0
        for future in as_completed(future_to_file):
            completed += 1
            if completed % 50 == 0:
                print(f"  å·²å¤„ç†: {completed}/{len(file_info_list)}")

            result = future.result()
            if result is not None:
                all_results.append(result)


                protein = result['protein']
                constraint = result['constraint']
                variant = result['variant']
                best_accessibility = result['best_accessibility']

                key = (protein, constraint, variant)
                result_dict[key].append(best_accessibility)

    print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(all_results)} ä¸ªæœ‰æ•ˆå®éªŒ")

    if not all_results:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®éªŒç»“æœ")
        return None

    print(f"æ”¶é›†åˆ° {len(all_results)} ä¸ªå®éªŒç»“æœ")


    proteins = set(r['protein'] for r in all_results)
    constraints = set(r['constraint'] for r in all_results)
    variants = set(r['variant'] for r in all_results)
    seeds = set(r['seed'] for r in all_results)

    print(f"è›‹ç™½è´¨æ•°é‡: {len(proteins)}")
    print(f"çº¦æŸç±»å‹: {sorted(list(constraints))}")
    print(f"å˜ä½“ç±»å‹: {sorted(list(variants))}")
    print(f"éšæœºç§å­: {sorted(list(seeds))}")


    match_rate = sum(r['amino_acids_match'] for r in all_results) / len(all_results) * 100
    print(f"æ°¨åŸºé…¸å®Œå…¨åŒ¹é…ç‡: {match_rate:.1f}%")


    proteins_sorted = sorted(list(proteins))
    constraints_sorted = sorted(list(constraints))
    variants_sorted = sorted(list(variants))


    columns = ['Protein']
    for constraint in constraints_sorted:
        for variant in variants_sorted:
            columns.append(f"{constraint}_{variant}")


    result_rows = []

    for protein in proteins_sorted:
        row = [protein]

        for constraint in constraints_sorted:
            for variant in variants_sorted:
                key = (protein, constraint, variant)
                if key in result_dict and len(result_dict[key]) > 0:
                    values = result_dict[key]
                    mean_val = np.mean(values)


                    if len(values) > 1:
                        std_val = np.std(values, ddof=1)
                        row.append(f"{mean_val:.4f}Â±{std_val:.4f}")
                    else:
                        row.append(f"{mean_val:.4f}Â±0.0000")
                else:
                    row.append("N/A")

        result_rows.append(row)


    if output_csv is None:
        output_csv = mpi_results_dir / f"mpi_summary_{mpi_results_dir.name}.csv"

    with open(output_csv, 'w') as f:

        f.write(','.join(columns) + '\n')

        for row in result_rows:
            f.write(','.join(map(str, row)) + '\n')


    print(f"\nğŸ“Š MPIå®éªŒæ±‡æ€»è¡¨æ ¼é¢„è§ˆ:")
    print("=" * 100)


    print(','.join(columns))


    for row in result_rows:
        print(','.join(map(str, row)))


    print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
    print(f"  â€¢ è›‹ç™½è´¨æ•°é‡: {len(proteins_sorted)}")
    print(f"  â€¢ çº¦æŸç±»å‹: {len(constraints_sorted)} ({', '.join(constraints_sorted)})")
    print(f"  â€¢ å˜ä½“ç±»å‹: {len(variants_sorted)} ({', '.join(variants_sorted)})")
    print(f"  â€¢ éšæœºç§å­æ•°: {len(seeds)}")
    print(f"  â€¢ æ€»å®éªŒæ¬¡æ•°: {len(all_results)}")


    all_values = [r['best_accessibility'] for r in all_results]
    overall_mean = np.mean(all_values)
    overall_std = np.std(all_values, ddof=1)
    overall_min = np.min(all_values)
    overall_max = np.max(all_values)

    print(f"\nğŸ¯ æ•´ä½“æ€§èƒ½ (best_accessibility):")
    print(f"  â€¢ å¹³å‡å€¼: {overall_mean:.4f} Â± {overall_std:.4f} kcal/mol")
    print(f"  â€¢ æœ€ä¼˜å€¼: {overall_min:.4f} kcal/mol")
    print(f"  â€¢ æœ€å·®å€¼: {overall_max:.4f} kcal/mol")


    print(f"\nğŸ“Š æŒ‰çº¦æŸç±»å‹ç»Ÿè®¡:")
    for constraint in constraints_sorted:
        constraint_values = [r['best_accessibility'] for r in all_results if r['constraint'] == constraint]
        if constraint_values:
            mean_val = np.mean(constraint_values)
            std_val = np.std(constraint_values, ddof=1) if len(constraint_values) > 1 else 0
            min_val = np.min(constraint_values)
            print(f"  {constraint.upper()}:")
            print(f"    â€¢ å¹³å‡: {mean_val:.4f} Â± {std_val:.4f}")
            print(f"    â€¢ æœ€ä¼˜: {min_val:.4f}")
            print(f"    â€¢ å®éªŒæ•°: {len(constraint_values)}")

    print(f"\nâœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_csv}")

    return result_rows

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python mpi_summary.py <mpi_results_dir> [output.csv] [num_workers]")
        print("ç¤ºä¾‹:")
        print("  python mpi_summary.py external_storage/results/mpi_flexible")
        print("  python mpi_summary.py external_storage/results/mpi_flexible results.csv")
        print("  python mpi_summary.py external_storage/results/mpi_flexible results.csv 16")
        return 1

    mpi_dir = Path(sys.argv[1])
    if not mpi_dir.exists():
        print(f"âŒ MPIå®éªŒç›®å½•ä¸å­˜åœ¨: {mpi_dir}")
        return 1

    output_csv = None
    if len(sys.argv) > 2 and sys.argv[2] != 'auto':
        output_csv = Path(sys.argv[2])

    num_workers = None
    if len(sys.argv) > 3:
        try:
            num_workers = int(sys.argv[3])
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„è¿›ç¨‹æ•°: {sys.argv[3]}, ä½¿ç”¨é»˜è®¤å€¼")

    result = generate_mpi_summary_table(mpi_dir, output_csv, num_workers)
    return 0 if result is not None else 1

if __name__ == "__main__":
    sys.exit(main())