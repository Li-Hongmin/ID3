#!/usr/bin/env python3
"""


"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

import torch
import numpy as np
import hashlib
from typing import Dict, List, Tuple

from id3.utils.constants import amino_acids_to_codons
from id3.utils.logging_config import setup_logging
from id3.optimizers.cai import BinarySearchCAIOptimizer

logger = setup_logging(level='INFO', name='prob_perturbation')


class ProbabilityPerturbationOptimizer:

    
    def __init__(self, sequence: str, target_cai: float = 0.8):
        self.sequence = sequence
        self.target_cai = target_cai
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        

        self.base_optimizer = BinarySearchCAIOptimizer(
            species='ecoli_bl21de3',
            device=self.device,
            amino_acid_sequence=sequence
        )
        

        self.history_hashes = set()
        self.unique_sequences = 0
        
    def perturb_probability(self, 
                           pi_original: torch.Tensor, 
                           perturbation_strength: float = 0.1,
                           positions_ratio: float = 0.1) -> torch.Tensor:
        """
        å¯¹æ¦‚çŽ‡åˆ†å¸ƒè¿›è¡Œè½»å¾®æ‰°åŠ¨
        
        Args:
            pi_original: åŽŸå§‹æ¦‚çŽ‡åˆ†å¸ƒ
            perturbation_strength: æ‰°åŠ¨å¼ºåº¦ (0-1)
            positions_ratio: æ‰°åŠ¨ä½ç½®çš„æ¯”ä¾‹
        
        Returns:
            æ‰°åŠ¨åŽçš„æ¦‚çŽ‡åˆ†å¸ƒ
        """
        pi_perturbed = pi_original.clone()
        seq_len = pi_perturbed.shape[0]
        

        num_positions = max(1, int(seq_len * positions_ratio))
        positions = np.random.choice(seq_len, num_positions, replace=False)
        
        for pos in positions:

            current_probs = pi_perturbed[pos]
            

            noise = torch.randn_like(current_probs) * perturbation_strength
            

            new_probs = current_probs + noise
            new_probs = torch.clamp(new_probs, min=0.0)
            

            if new_probs.sum() > 0:
                new_probs = new_probs / new_probs.sum()
            else:

            
            pi_perturbed[pos] = new_probs
        
        return pi_perturbed
    
    def optimize_with_perturbation(self, 
                                  pi_original: torch.Tensor,
                                  max_attempts: int = 10) -> Dict:
        """
        ä½¿ç”¨æ¦‚çŽ‡æ‰°åŠ¨ç­–ç•¥ä¼˜åŒ–
        
        1. å¯¹åŽŸå§‹æ¦‚çŽ‡è¿›è¡Œè½»å¾®æ‰°åŠ¨
        2. ç”¨äºŒåˆ†æŸ¥æ‰¾æ‰¾åˆ°æ»¡è¶³CAIâ‰¥0.8çš„åºåˆ—
        3. å¦‚æžœé‡å¤ï¼Œå¢žåŠ æ‰°åŠ¨å¼ºåº¦é‡è¯•
        """
        best_result = None

        
        for attempt in range(max_attempts):

            if attempt == 0:

                pi_perturbed = pi_original
            else:

                current_strength = perturbation_strength * (1 + attempt * 0.5)

                


                
                pi_perturbed = self.perturb_probability(
                    pi_original, 
                    perturbation_strength=current_strength,
                    positions_ratio=positions_ratio
                )
            

            result, metadata = self.base_optimizer.optimize(
                pi_accessibility=pi_perturbed,
                target_cai=self.target_cai,
                amino_acid_sequence=self.sequence
            )
            

            indices = result.argmax(dim=-1).cpu().numpy()
            seq_hash = hashlib.md5(indices.tobytes()).hexdigest()
            

            if seq_hash not in self.history_hashes:

                self.history_hashes.add(seq_hash)
                self.unique_sequences += 1
                
                return {
                    'sequence': result,
                    'indices': indices,
                    'cai': metadata['final_cai'],
                    'gamma': metadata['gamma'],
                    'constraint_satisfied': metadata['constraint_satisfied'],
                    'perturbation_strength': current_strength if attempt > 0 else 0,
                    'attempt': attempt + 1,
                    'unique_sequences': self.unique_sequences,
                    'is_duplicate': False
                }
            

            if best_result is None or metadata['final_cai'] > best_result['cai']:
                best_result = {
                    'sequence': result,
                    'indices': indices,
                    'cai': metadata['final_cai'],
                    'gamma': metadata['gamma'],
                    'constraint_satisfied': metadata['constraint_satisfied'],
                    'perturbation_strength': current_strength if attempt > 0 else 0,
                    'attempt': attempt + 1,
                    'unique_sequences': self.unique_sequences,
                    'is_duplicate': True
                }
        

        return best_result


def test_perturbation_strategy():
    """æµ‹è¯•æ¦‚çŽ‡æ‰°åŠ¨ç­–ç•¥çš„æ•ˆæžœ"""
    logger.info("="*80)
    logger.info("æ¦‚çŽ‡æ‰°åŠ¨ç­–ç•¥æµ‹è¯•")
    logger.info("="*80)
    

    seq_length = 500
    amino_acids = list('ACDEFGHIKLMNPQRSTVWY')
    weights = np.array([8, 3, 6, 6, 7, 4, 2, 6, 5, 9, 2, 4, 2, 4, 5, 7, 5, 1, 3, 7])
    weights = weights / weights.sum()
    test_sequence = ''.join(np.random.choice(amino_acids, seq_length, p=weights))
    
    logger.info(f"æµ‹è¯•åºåˆ—é•¿åº¦: {seq_length} aa")
    logger.info(f"ç›®æ ‡CAI: 0.8")
    

    optimizer = ProbabilityPerturbationOptimizer(test_sequence, target_cai=0.8)
    

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    pi_original = torch.rand(seq_length, 6, device=device)
    for pos in range(seq_length):
        if pi_original[pos].sum() > 0:
            pi_original[pos] = pi_original[pos] / pi_original[pos].sum()
    

    num_iterations = 20
    results = []
    
    logger.info(f"\nå¼€å§‹{num_iterations}æ¬¡è¿­ä»£æµ‹è¯•...")
    logger.info("-"*60)
    
    for i in range(num_iterations):

        if i % 5 == 0 and i > 0:

            pi_original = torch.rand(seq_length, 6, device=device)
            for pos in range(seq_length):
                if pi_original[pos].sum() > 0:
                    pi_original[pos] = pi_original[pos] / pi_original[pos].sum()
            logger.info(f"  æ›´æ¢åŸºç¡€æ¦‚çŽ‡åˆ†å¸ƒ")
        

        result = optimizer.optimize_with_perturbation(pi_original)
        results.append(result)
        
        logger.info(f"è¿­ä»£ {i+1}:")
        logger.info(f"  CAI: {result['cai']:.4f} {'âœ…' if result['constraint_satisfied'] else 'âŒ'}")
        logger.info(f"  æ‰°åŠ¨å¼ºåº¦: {result['perturbation_strength']*100:.1f}%")
        logger.info(f"  å°è¯•æ¬¡æ•°: {result['attempt']}")
        logger.info(f"  æ˜¯å¦é‡å¤: {'æ˜¯' if result['is_duplicate'] else 'å¦'}")
        logger.info(f"  å”¯ä¸€åºåˆ—æ€»æ•°: {result['unique_sequences']}")
    

    logger.info("\n" + "="*80)
    logger.info("æ•ˆæžœåˆ†æž")
    logger.info("="*80)
    

    unique_count = optimizer.unique_sequences
    duplicate_count = sum(1 for r in results if r['is_duplicate'])
    
    logger.info(f"\nðŸ“Š å¤šæ ·æ€§:")
    logger.info(f"  å”¯ä¸€åºåˆ—: {unique_count}/{num_iterations}")
    logger.info(f"  é‡å¤æ¬¡æ•°: {duplicate_count}")
    logger.info(f"  å¤šæ ·æ€§çŽ‡: {unique_count/num_iterations*100:.1f}%")
    

    cais = [r['cai'] for r in results]
    satisfied = sum(1 for r in results if r['constraint_satisfied'])
    
    logger.info(f"\nðŸ“ˆ CAIæ€§èƒ½:")
    logger.info(f"  çº¦æŸæ»¡è¶³çŽ‡: {satisfied}/{num_iterations} ({satisfied/num_iterations*100:.1f}%)")
    logger.info(f"  å¹³å‡CAI: {np.mean(cais):.4f}")
    logger.info(f"  CAIèŒƒå›´: [{min(cais):.4f}, {max(cais):.4f}]")
    

    perturbations = [r['perturbation_strength'] for r in results if r['perturbation_strength'] > 0]
    if perturbations:
        logger.info(f"\nðŸŽ¯ æ‰°åŠ¨ç­–ç•¥:")
        logger.info(f"  å¹³å‡æ‰°åŠ¨å¼ºåº¦: {np.mean(perturbations)*100:.1f}%")
        logger.info(f"  æœ€å¤§æ‰°åŠ¨å¼ºåº¦: {max(perturbations)*100:.1f}%")
    

    attempts = [r['attempt'] for r in results]
    logger.info(f"\nâš¡ æ•ˆçŽ‡:")
    logger.info(f"  å¹³å‡å°è¯•æ¬¡æ•°: {np.mean(attempts):.1f}")
    logger.info(f"  æœ€å¤šå°è¯•æ¬¡æ•°: {max(attempts)}")
    

    logger.info(f"\nðŸ’¡ å¯¹æ¯”åˆ†æž:")
    logger.info(f"  åŽŸå§‹äºŒåˆ†æŸ¥æ‰¾: é‡å¤çŽ‡100%")
    logger.info(f"  æ¦‚çŽ‡æ‰°åŠ¨ç­–ç•¥: é‡å¤çŽ‡{duplicate_count/num_iterations*100:.1f}%")
    logger.info(f"  æ”¹è¿›æ•ˆæžœ: {(1-duplicate_count/num_iterations)*100:.1f}%å¤šæ ·æ€§æå‡")
    
    if satisfied == num_iterations:
        logger.info(f"  âœ… å®Œç¾Žï¼æ‰€æœ‰åºåˆ—éƒ½æ»¡è¶³CAIâ‰¥0.8çº¦æŸ")
    
    return results


def test_perturbation_strength_impact():

    logger.info("\n" + "="*80)

    logger.info("="*80)
    

    seq_length = 300
    amino_acids = list('ACDEFGHIKLMNPQRSTVWY')
    weights = np.array([8, 3, 6, 6, 7, 4, 2, 6, 5, 9, 2, 4, 2, 4, 5, 7, 5, 1, 3, 7])
    weights = weights / weights.sum()
    test_sequence = ''.join(np.random.choice(amino_acids, seq_length, p=weights))
    

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    pi_original = torch.rand(seq_length, 6, device=device)
    for pos in range(seq_length):
        if pi_original[pos].sum() > 0:
            pi_original[pos] = pi_original[pos] / pi_original[pos].sum()
    

    strengths = [0.01, 0.05, 0.1, 0.15, 0.2, 0.3]
    

    logger.info("-"*60)
    
    for strength in strengths:
        optimizer = ProbabilityPerturbationOptimizer(test_sequence, target_cai=0.8)
        

        pi_perturbed = optimizer.perturb_probability(
            pi_original, 
            perturbation_strength=strength,
            positions_ratio=0.2
        )
        
        result, metadata = optimizer.base_optimizer.optimize(
            pi_accessibility=pi_perturbed,
            target_cai=0.8,
            amino_acid_sequence=test_sequence
        )
        

        result_original, _ = optimizer.base_optimizer.optimize(
            pi_accessibility=pi_original,
            target_cai=0.8,
            amino_acid_sequence=test_sequence
        )
        
        indices_perturbed = result.argmax(dim=-1).cpu().numpy()
        indices_original = result_original.argmax(dim=-1).cpu().numpy()
        
        difference = np.sum(indices_perturbed != indices_original)
        

        logger.info(f"  CAI: {metadata['final_cai']:.4f}")


    






if __name__ == "__main__":

    

    results = test_perturbation_strategy()
    

    test_perturbation_strength_impact()
    

