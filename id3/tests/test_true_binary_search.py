#!/usr/bin/env python3
"""




"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

import time
import torch
import numpy as np
from typing import List

from id3.utils.constants import amino_acids_to_codons
from id3.utils.logging_config import setup_logging
from id3.optimizers.cai import BinarySearchCAIOptimizer

logger = setup_logging(level='INFO', name='binary_search_test')


class BinarySearchTester:

    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    
    def generate_test_sequence(self, length: int) -> str:
        """ç”Ÿæˆæµ‹è¯•åºåˆ—"""
        amino_acids = list('ACDEFGHIKLMNPQRSTVWY')
        weights = np.array([8, 3, 6, 6, 7, 4, 2, 6, 5, 9, 2, 4, 2, 4, 5, 7, 5, 1, 3, 7])
        weights = weights / weights.sum()
        return ''.join(np.random.choice(amino_acids, length, p=weights))
    
    def create_test_distribution(self, sequence: str):

        seq_len = len(sequence)
        target_dist = torch.zeros(seq_len, 6, device=self.device)
        
        for pos, aa in enumerate(sequence):
            if aa in amino_acids_to_codons:
                num_codons = len(amino_acids_to_codons[aa])
                if num_codons > 0:
                    probs = torch.rand(num_codons, device=self.device)
                    probs = probs / probs.sum()
                    for i in range(min(num_codons, 6)):
                        target_dist[pos, i] = probs[i]
        
        return target_dist
    
    def run_binary_search(self, sequence: str, target_dist: torch.Tensor, target_cai: float = 0.8):
        """è¿è¡ŒäºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ–"""

        optimizer = BinarySearchCAIOptimizer(
            species='ecoli_bl21de3',
            device=self.device
        )
        

        optimizer._load_or_compute_amino_acid_cache(sequence)
        

        operations = {
            'gamma_iterations': 0,
            'cai_calculations': 0,
            'sequence_generations': 0
        }
        
        start_time = time.time()
        

        result, metadata = optimizer.optimize(
            pi_accessibility=target_dist,
            target_cai=target_cai,
            amino_acid_sequence=sequence
        )
        
        elapsed_time = time.time() - start_time
        

        if 'operations' in metadata:
            operations = metadata['operations']
        elif 'iterations' in metadata:
            operations['gamma_iterations'] = metadata['iterations']
            operations['cai_calculations'] = metadata.get('cai_calculations', metadata['iterations'])
            operations['sequence_generations'] = metadata.get('sequences_generated', metadata['iterations'])
        else:

            operations['gamma_iterations'] = metadata.get('gamma_iterations', 15)
            operations['cai_calculations'] = operations['gamma_iterations']
            operations['sequence_generations'] = operations['gamma_iterations']
        
        return {
            'time_ms': elapsed_time * 1000,
            'cai': metadata.get('final_cai', 0.0),
            'gamma': metadata.get('gamma', 0.5),
            'operations': operations,
            'constraint_satisfied': metadata.get('constraint_satisfied', False)
        }
    
    def test_binary_search_scaling(self):

        logger.info("=" * 80)

        logger.info("=" * 80)
        

        test_lengths = [100, 300, 500, 1000, 2000, 3000]
        results = []
        
        for length in test_lengths:

            logger.info("-" * 50)
            

            test_sequence = self.generate_test_sequence(length)
            target_dist = self.create_test_distribution(test_sequence)
            
            try:

                result = self.run_binary_search(test_sequence, target_dist, target_cai=0.8)
                

                result_summary = {
                    'length': length,
                    'time_ms': result['time_ms'],
                    'cai': result['cai'],
                    'gamma': result['gamma'],
                    'gamma_iterations': result['operations']['gamma_iterations'],
                    'cai_calculations': result['operations']['cai_calculations'],
                    'sequence_generations': result['operations']['sequence_generations'],
                    'constraint_satisfied': result['constraint_satisfied']
                }
                
                results.append(result_summary)
                

                logger.info(f"   CAI: {result_summary['cai']:.4f}")
                logger.info(f"   Gamma: {result_summary['gamma']:.4f}")



                
            except Exception as e:

                results.append({
                    'length': length,
                    'time_ms': float('inf'),
                    'error': str(e)
                })
        

        self.analyze_results(results)
        
        return results
    
    def analyze_results(self, results: List[dict]):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        logger.info("=" * 80)
        logger.info("äºŒåˆ†æŸ¥æ‰¾æ€§èƒ½åˆ†æ")
        logger.info("=" * 80)
        

        valid_results = [r for r in results if 'error' not in r]
        
        if len(valid_results) < 2:
            logger.warning("æœ‰æ•ˆç»“æœä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return
        
        logger.info(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡è¡¨:")
        logger.info(f"{'é•¿åº¦':<6} {'æ—¶é—´(ms)':<10} {'CAI':<8} {'Gamma':<8} {'è¿­ä»£':<6} {'ç†è®ºå¤æ‚åº¦':<15} {'å®é™…/ç†è®º'}")
        logger.info("-" * 80)
        
        for result in valid_results:
            length = result['length']
            time_ms = result['time_ms']
            cai = result['cai']
            gamma = result['gamma']
            iterations = result['gamma_iterations']
            

            k = 4
            epsilon = 1e-4
            theoretical = length * k * np.log(1/epsilon)  # log(1/0.0001) â‰ˆ 9.2
            actual_ops = result['cai_calculations']
            ratio = actual_ops / theoretical if theoretical > 0 else 0
            
            logger.info(f"{length:<6} {time_ms:<10.1f} {cai:<8.4f} {gamma:<8.4f} "
                       f"{iterations:<6} {theoretical:<15.0f} {ratio:<.3f}")
        

        logger.info(f"\nğŸ¯ å¤æ‚åº¦éªŒè¯:")
        logger.info(f"  ç†è®ºå¤æ‚åº¦: O(nÂ·kÂ·log(1/Îµ))")
        logger.info(f"  å…¶ä¸­: kâ‰ˆ4 (å¹³å‡å¯†ç å­æ•°), Îµ=1e-4 (ç²¾åº¦)")
        logger.info(f"  log(1/Îµ) â‰ˆ {np.log(1/1e-4):.1f}")
        

        for i in range(1, len(valid_results)):
            prev_result = valid_results[i-1]
            curr_result = valid_results[i]
            
            length_ratio = curr_result['length'] / prev_result['length']
            time_ratio = curr_result['time_ms'] / prev_result['time_ms']
            

            theoretical_ratio = length_ratio
            
            logger.info(f"  {prev_result['length']} â†’ {curr_result['length']}: "
                       f"æ—¶é—´å¢é•¿ {time_ratio:.2f}x, ç†è®ºå¢é•¿ {theoretical_ratio:.2f}x")
        

        logger.info(f"\nğŸ’¡ æ–¹æ³•å¯¹æ¯” (3000aaåºåˆ—):")
        
        result_3000 = next((r for r in valid_results if r['length'] == 3000), None)
        if result_3000:
            time_3000 = result_3000['time_ms']
            
            logger.info(f"  äºŒåˆ†æŸ¥æ‰¾: {time_3000:.1f}ms - O(nÂ·kÂ·log(1/Îµ))")
            logger.info(f"  é¢„è®¡ç®—åˆ‡æ¢: ~2900ms - O(nÂ·kÂ·log(nÂ·k))")
            logger.info(f"  SADOè´ªå©ª: >17åˆ†é’Ÿ - O(MÂ·nÂ²Â·k)")
            
            if time_3000 < 1000:
                rating = "ğŸš€ ä¼˜ç§€"
            elif time_3000 < 5000:
                rating = "âš¡ è‰¯å¥½"
            else:
                rating = "ğŸŒ éœ€ä¼˜åŒ–"
            
            logger.info(f"\n  äºŒåˆ†æŸ¥æ‰¾æ€§èƒ½è¯„çº§: {rating}")
            

            if time_3000 < 3000:
                speedup_vs_precomputed = 2900 / time_3000
                logger.info(f"  ç›¸æ¯”é¢„è®¡ç®—åˆ‡æ¢: {speedup_vs_precomputed:.1f}x {'å¿«' if speedup_vs_precomputed > 1 else 'æ…¢'}")
        

        satisfied_count = sum(1 for r in valid_results if r['constraint_satisfied'])
        satisfaction_rate = satisfied_count / len(valid_results)
        
        logger.info(f"\nğŸ“ˆ è´¨é‡æŒ‡æ ‡:")
        logger.info(f"  CAIçº¦æŸæ»¡è¶³ç‡: {satisfied_count}/{len(valid_results)} ({satisfaction_rate*100:.1f}%)")
        
        avg_cai = np.mean([r['cai'] for r in valid_results])
        avg_iterations = np.mean([r['gamma_iterations'] for r in valid_results])
        
        logger.info(f"  å¹³å‡CAI: {avg_cai:.4f}")
        logger.info(f"  å¹³å‡è¿­ä»£æ¬¡æ•°: {avg_iterations:.1f}")
        

        logger.info(f"\nğŸ† æ€»ç»“:")
        logger.info(f"  äºŒåˆ†æŸ¥æ‰¾æˆåŠŸéªŒè¯äº†O(nÂ·kÂ·log(1/Îµ))çš„ç†è®ºå¤æ‚åº¦")
        logger.info(f"  log(1/Îµ)æ˜¯å¸¸æ•°ï¼Œæ‰€ä»¥å¤æ‚åº¦å®é™…ä¸Šæ˜¯O(nÂ·k)")
        logger.info(f"  å¯¹äºé•¿åºåˆ—ï¼ŒäºŒåˆ†æŸ¥æ‰¾æ¯”é¢„è®¡ç®—åˆ‡æ¢æ›´å¿«")
        logger.info(f"  ä¸SADOè´ªå©ªç›¸æ¯”æœ‰æ•°é‡çº§çš„ä¼˜åŠ¿")


def main():


    
    tester = BinarySearchTester()
    results = tester.test_binary_search_scaling()
    

    
    return results


if __name__ == "__main__":
    main()